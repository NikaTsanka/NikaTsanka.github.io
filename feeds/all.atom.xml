<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>GammaCode</title><link href="https://nikatsanka.github.io/" rel="alternate"></link><link href="https://nikatsanka.github.io/feeds/all.atom.xml" rel="self"></link><id>https://nikatsanka.github.io/</id><updated>2017-07-01T00:00:00-04:00</updated><entry><title>Comparing Edge Detection Methods</title><link href="https://nikatsanka.github.io/comparing-edge-detection-methods.html" rel="alternate"></link><published>2017-07-01T00:00:00-04:00</published><updated>2017-07-01T00:00:00-04:00</updated><author><name>Nika Tsankashvili</name></author><id>tag:nikatsanka.github.io,2017-07-01:/comparing-edge-detection-methods.html</id><summary type="html">&lt;p&gt;Comparing different edge detection methods. Let's see which one is the best.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Have you ever wondered which edge detection methods are best for given images? Yeah? So am I, so let's compare them.&lt;/p&gt;
&lt;p&gt;We will be implementing some of the most commonly used methods and also using methods from OpenCV and PIL&lt;/p&gt;
&lt;p&gt;We will be comparing the following methods:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sobel edge detector&lt;/li&gt;
&lt;li&gt;Prewitt edge detector&lt;/li&gt;
&lt;li&gt;Laplacian edge detector&lt;/li&gt;
&lt;li&gt;Canny edge detector&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Sobel Operator&lt;/h2&gt;
&lt;p&gt;The sobel is one of the most commonly used edge detectors. It is based on convolving the image with a small, separable, and integer valued filter in horizontal and vertical direction and is therefore relatively inexpensive in terms of computations. The Sobel edge enhancement filter has the advantage of providing differencing (which gives the edge response) and smoothing (which reduces noise) concurrently. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Sobel" src="/images/sobel-mask.png"&gt;&lt;/p&gt;
&lt;p&gt;Here is a python implementation of Sobel operator&lt;/p&gt;
&lt;script src="https://gist.github.com/NikaTsanka/868a33330c26e775e70b18bb96615d39.js"&gt;&lt;/script&gt;

&lt;p&gt;Results:&lt;/p&gt;
&lt;p&gt;&lt;img alt="dancing-spider" src="/images/dancing-spider.jpg"&gt; 
&lt;img alt="dancing-spider-sobel" src="/images/dancing-spider-sobel.png"&gt; &lt;/p&gt;
&lt;p&gt;In this example we apply the mask on the gray-scale image, however we can produce a better result by applying the mask on each RGB channel. &lt;/p&gt;
&lt;script src="https://gist.github.com/NikaTsanka/067cc011b339ecb2dc86820d4a8999b7.js"&gt;&lt;/script&gt;

&lt;p&gt;Results: One channel(left), RGB channel(right).&lt;/p&gt;
&lt;p&gt;&lt;img alt="dancing-spider-sobel" src="/images/dancing-spider-sobel.png"&gt; 
&lt;img alt="dancing-spider-sobel-rgb" src="/images/dancing-spider-sobel-rgb.png"&gt; &lt;/p&gt;
&lt;p&gt;You can see a slight improvement but note that it's computationally more costly.&lt;/p&gt;
&lt;h2&gt;Prewitt’s Operator&lt;/h2&gt;
&lt;p&gt;Prewitt operator is similar to the Sobel operator and is used for detecting vertical and horizontal edges in images. However, unlike the Sobel, this operator does not place any emphasis on the pixels that are closer to the center of the mask. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Prewitt" src="/images/prewitt-mask.png"&gt;&lt;/p&gt;
&lt;p&gt;The only differance is the mask&lt;/p&gt;
&lt;script src="https://gist.github.com/NikaTsanka/74c862540bacd1c35ab52379dec032c7.js"&gt;&lt;/script&gt;

&lt;p&gt;Result:&lt;/p&gt;
&lt;p&gt;&lt;img alt="dancing-spider-sobel-rgb" src="/images/dancing-spider-prewitt.png"&gt;&lt;/p&gt;
&lt;h2&gt;Laplacian Operator&lt;/h2&gt;
&lt;p&gt;Laplacian is somewhat different from the methods we have discussed so far.
Unlike the Sobel and Prewitt’s edge detectors, the Laplacian edge detector uses only one kernel. It calculates second order derivatives in a single pass. Two commonly used small kernels are:&lt;/p&gt;
&lt;p&gt;&lt;img alt="laplacian-mask" src="/images/lap_mask-2.png"&gt;&lt;/p&gt;
&lt;p&gt;Because these masks are approximating a second derivative measurement on the image, they are very sensitive to noise. To correct this, the image is often Gaussian smoothed before applying the Laplacian filter.&lt;/p&gt;
&lt;p&gt;We can also convolve gaussian mask with the Laplacian mask and apply to the image in one pass. I will explain how to convolve one kernel with another in a separate tutorial. However, we will be applying them separately in the following example. To make things easier we will be using OpenCV.&lt;/p&gt;
&lt;script src="https://gist.github.com/NikaTsanka/496425bc19eb9db2f8ffc665754fea1d.js"&gt;&lt;/script&gt;

&lt;p&gt;Results:&lt;/p&gt;
&lt;p&gt;&lt;img alt="shapes-lap" src="/images/dancing-spider-lap.png"&gt; &lt;/p&gt;
&lt;h2&gt;Canny Operator&lt;/h2&gt;
&lt;p&gt;Canny edge detector is probably the most commonly used and most effective method, it can have it's own tutorial, because it's much more complex edge detecting method then the ones described above. However, I will try to make it short and easy to understand. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Smooth the image with a Gaussian filter to reduce noise.&lt;/li&gt;
&lt;li&gt;Compute gradient of using any of the gradient operators Sobel or Prewitt.&lt;/li&gt;
&lt;li&gt;Extract edge points: Non-maximum suppression.&lt;/li&gt;
&lt;li&gt;Linking and thresholding: Hysteresis &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;First two steps are very straight forward, note that in the second step we are also computing the orientation of gradients "theta = arctan(Gy / Gx)" Gy and Gx are gradient x direction and y direction respectively. &lt;/p&gt;
&lt;p&gt;Now let's talk about Non-maximum suppression and what it does. In this step we are trying to relate the edge direction to a direction that can be traced along the edges based on the previously calculated gradient strengths and edge directions. At each pixel location we have four possible directions. We check all directions if the gradient is maximum at this point. Perpendicular pixel values are compared with the value in the edge direction. If their value is lower than the pixel on the edge then they are suppressed.
After this step we will get broken thin edges that needs to be fixed, so let's move on to the next step.&lt;/p&gt;
&lt;p&gt;Hysteresis is a way of linking the broken lines produced in the previous step. This is done by iterating over the pixels and checking if the current pixel is an edge. If it's an edge then check surrounding area for edges. If they have the same direction then we mark them as an edge pixel. We also use 2 thresholds, a high and low. If the pixels is greater than lower threshold it is marked as an edge. Then pixels that are greater than the lower throrshold and also are greater than high threshold, are also selected as strong edge pixels. When there are no more changes to the image we stop. &lt;/p&gt;
&lt;p&gt;Now let's looked the code:&lt;/p&gt;
&lt;script src="https://gist.github.com/NikaTsanka/ffbf8cd4ca3b5fe8ce3822e033c5ca43.js"&gt;&lt;/script&gt;

&lt;p&gt;Results:&lt;/p&gt;
&lt;p&gt;&lt;img alt="shapes-lap" src="/images/dancing-spider-canny.png"&gt; &lt;/p&gt;
&lt;p&gt;If you have any questions or I messed up somewhere, please emails me at nikatsanka@gmail.com&lt;/p&gt;</content></entry><entry><title>Fourier Transform by Example</title><link href="https://nikatsanka.github.io/fourier-transform-by-example.html" rel="alternate"></link><published>2017-06-12T00:00:00-04:00</published><updated>2017-06-12T00:00:00-04:00</updated><author><name>Nika Tsankashvili</name></author><id>tag:nikatsanka.github.io,2017-06-12:/fourier-transform-by-example.html</id><summary type="html">&lt;p&gt;Short tutorial explaining how to computer Discrete Fourier Transform by doing all the computations by hand.&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this short tutorial I will explain how to computer Discrete Fourier Transform by Example. The reason is simple. It is always easier to understand something new by actually doing, so that's what we will be doing here. &lt;/p&gt;
&lt;p&gt;I will be using image transformations as an example. So let's jump into it. &lt;/p&gt;
&lt;p&gt;I'm not going to go into much details of what Fourier transform is but rather focus more on actual examples. Here is a really good place to start &lt;a href="https://www.youtube.com/watch?v=mkGsMWi_j4Q"&gt;Discrete Fourier Transform - Simple Step by Step&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We know that Discrete Fourier Transform (DFT) goes from spatial(time) domain to frequency domain and vice versa. Going from spatial domain to frequency domain is called forward DFT and going from the frequency domain to spatial domain is called inverse DFT.&lt;/p&gt;
&lt;h2&gt;Forward Discrete Fourier Transform&lt;/h2&gt;
&lt;p&gt;&lt;img alt="DFT" src="/images/d-fourier-f.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Let's consider a list of real numbers: 36, 22, 45, 15. Thus, we have F = 36, 22, 45, 15. N = 4. u = (0,1,2,3). x = (0,1,2,3). Now let's compute the coefficients for these numbers.&lt;/p&gt;
&lt;p&gt;So we have F(u) = u*e^(-i*2*π*u*x/4)&lt;/p&gt;
&lt;p&gt;Since x = 0 we get the same number for all numbers.&lt;/p&gt;
&lt;p&gt;x = 0: F(0) = (36*e^(-i*2*π*0*0/4) + 22*e^(-i*2*π*0*1/4) + 45*e^(-i*2*π*0*2/4) + 15*e^(-i*2*π*0*3/4)) / 4 = 29.5 + 0i&lt;/p&gt;
&lt;p&gt;x = 1: F(1) = 36*e^(-i*2*π*1*0/4) + 22*e^(-i*2*π*1*1/4) + 45*e^(-i*2*π*1*2/4) + 15*e^(-i*2*π*1*3/4) = 36 + 22*cos(-π/2) - 22*i*sin(-π/2) + 45*cos(-π) - 45*i*sin(-π) + 15*cos(-π*3/2) - 15*i*sin(-π*3/2) = 36 + 0 - 45 + 0 + (0i - 22.00i + 0i + 15.00i) = -9/4 + (-7i/4) = -2.25 - 1.75i &lt;/p&gt;
&lt;p&gt;x = 2: F(2) = 36*e^(-i*2*π*2*0/4) + 22*e^(-i*2*π*2*1/4) + 45*e^(-i*2*π*2*2/4) + 15*e^(-i*2*π*2*3/4) = 36 + 22*cos(-π) - 22*i*sin(-π) + 45*cos(-π*2) - 45*i*sin(-π*2) + 15*cos(-π*3) - 15*i*sin(-π*3) = 36 - 22. + 45. - 15. + (0i + 0i + 0i + 0i) = 44/4 + (0i/4) = 11 + 0i&lt;/p&gt;
&lt;p&gt;x = 3: F(3) = 36*e^(-i*2*π*3*0/4) + 22*e^(-i*2*π*3*1/4) + 45*e^(-i*2*π*3*2/4) + 15*e^(-i*2*π*3*3/4) = 36 + 22*cos(-π*3/2) - 22*i*sin(-π*3/2) + 45*cos(-π*3) - 45*i*sin(-π*3) + 15*cos(-π*9/2) - 15*i*sin(-π*9/2) = 36 + 0 - 45 - 0 + (0i + 22.00i - 0i - 15.00i) = -9/4 + (7i/4) = -2.25 + 1.75i &lt;/p&gt;
&lt;p&gt;At this point you can take these coefficients and perform your operations such as filtering, convolution or what have you. &lt;/p&gt;
&lt;p&gt;Also now that we have the coefficients we can express them in terms of magnitude and phase. &lt;/p&gt;
&lt;h3&gt;Magnitude&lt;/h3&gt;
&lt;p&gt;&lt;img alt="FS" src="/images/spectrum.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Magnitude tells &lt;strong&gt;how much&lt;/strong&gt; of a certain frequency component is present. &lt;/p&gt;
&lt;p&gt;F(0) = sqrt(29.5^2 + 0^2) = 29.50&lt;/p&gt;
&lt;p&gt;F(1) = sqrt(-2.25^2 - 1.75^2) = 2.85&lt;/p&gt;
&lt;p&gt;F(2) = sqrt(11^2 + 0^2) = 11.00&lt;/p&gt;
&lt;p&gt;F(3) = sqrt(-2.25^2 + 1.75^2) = 2.85&lt;/p&gt;
&lt;h3&gt;Phase&lt;/h3&gt;
&lt;p&gt;&lt;img alt="FP" src="/images/phase.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Phase tells &lt;strong&gt;where&lt;/strong&gt; the frequency component is in the image.&lt;/p&gt;
&lt;p&gt;Φ(0) = atan2(0 / 29.5) = 0&lt;/p&gt;
&lt;p&gt;Φ(1) = atan2(-1.75 / -2.25) = -2.48&lt;/p&gt;
&lt;p&gt;Φ(2) = atan2(0 / 11) = 0&lt;/p&gt;
&lt;p&gt;Φ(3) = atan2(1.75 / -2.25) = 2.48&lt;/p&gt;
&lt;h2&gt;Inverse Discrete Fourier Transform&lt;/h2&gt;
&lt;p&gt;&lt;img alt="DFT" src="/images/d-fourier-i.jpg"&gt;&lt;/p&gt;
&lt;p&gt;After performing some operations we need to do the inverse.&lt;/p&gt;
&lt;p&gt;Now let's reconstruct the list from the coefficients that we just computed.&lt;/p&gt;
&lt;p&gt;f(0) = (29.5 + 0i)*e^(i*2*π*0*0/4) + (-2.25 - 1.75i)*e^(i*2*π*0*1/4) + (11 + 0i)*e^(i*2*π*0*2/4) + (-2.25 + 1.75i)*e^(i*2*π*0*3/4) = 29.5 - 2.25 + 11 - 2.25 = 36.00&lt;/p&gt;
&lt;p&gt;f(1) = (29.5 + 0i)*e^(i*2*π*1*0/4) + (-2.25 - 1.75i)*e^(i*2*π*1*1/4) + (11 + 0i)*e^(i*2*π*1*2/4) + (-2.25 + 1.75i)*e^(i*2*π*1*3/4) = 29.5 + (-2.25*cos(π/2) + 1.75*sin(π/2) - i*(2.25*sin(π/2) - 1.75*cos(π/2))) + (11.00*cos(π) - 0*sin(π) + i*(11.00*sin(π) + 0*cos(π))) + (-2.25*cos(π*3/2) - 1.75*sin(π*3/2) + i*(2.25*sin(π*3/2) + 1.75*cos(π*3/2))) = 29.5 + 1.75 - 11 + 1.75 = 22.00&lt;/p&gt;
&lt;p&gt;f(2) = (29.5 + 0i)*e^(i*2*π*2*0/4) + (-2.25 - 1.75i)*e^(i*2*π*2*1/4) + (11 + 0i)*e^(i*2*π*2*2/4) + (-2.25 + 1.75i)*e^(i*2*π*2*3/4) = 29.5 + (-2.25*cos(π) + 1.75*sin(π) - i*(2.25*sin(π) - 1.75*cos(π))) + (11.00*cos(π*2) - 0*sin(π*2) + i*(11.00*sin(π*2) + 0*cos(π*2))) + (-2.25*cos(π*3) - 1.75*sin(π*3) + i*(2.25*sin(π*3) + 1.75*cos(π*3))) = 29.5 + 2.25 + 11 + 2.25 = 45.00&lt;/p&gt;
&lt;p&gt;f(3) = (29.5 + 0i)*e^(i*2*π*3*0/4) + (-2.25 - 1.75i)*e^(i*2*π*3*1/4) + (11 + 0i)*e^(i*2*π*3*2/4) + (-2.25 + 1.75i)*e^(i*2*π*3*3/4) = 29.5 + (-2.25*cos(π*3/2) + 1.75*sin(π*3/2) - i*(2.25*sin(π*3/2 - 1.75*cos(π*3/2))) + (11.00*cos(π*3) - 0*sin(π*3) + i*(11.00*sin(π*3) + 0*cos(π*3))) + (-2.25*cos(π*9/2) - 1.75*sin(π*9/2) + i*(2.25*sin(π*9/2) + 1.75*cos(π*9/2))) = 29.50 - 1.75 - 11 - 1.75 = 15.00&lt;/p&gt;
&lt;p&gt;So we got 36, 22, 45, 15. We are getting the same numbers because we didn't make any changes in the frequency domain. &lt;/p&gt;
&lt;p&gt;Now let's write a simple python script to compute Discrete Fourier Transforms. Why? Because sometimes it's easier to understand what we are actually doing by looking at the code.&lt;/p&gt;
&lt;script src="https://gist.github.com/NikaTsanka/937eeefb284c14b2bb3c50510f9e8bdc.js"&gt;&lt;/script&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;p&gt;Coefficients:
(29.50, 0.00),
(-2.25, -1.75),
(11.00, 0.00),
(-2.25, 1.75),&lt;/p&gt;
&lt;p&gt;Magnitude:
29.50,
2.85,
11.00,
2.85,&lt;/p&gt;
&lt;p&gt;Phase:
0.00,
-2.48,
0.00,
2.48,&lt;/p&gt;
&lt;p&gt;Our List:
(36.00, 0.00),
(22.00, 0.00),
(45.00, 0.00),
(15.00, 0.00),&lt;/p&gt;
&lt;p&gt;&lt;img alt="MPP" src="/images/mag-phase.png"&gt;&lt;/p&gt;
&lt;p&gt;These don't look good because we didn't have a lot of numbers.&lt;/p&gt;
&lt;p&gt;And that's it. Next time I will explain how to do &lt;strong&gt;Fast Fourier Transform&lt;/strong&gt; which is super cool. &lt;/p&gt;
&lt;p&gt;If you have any questions or I messed up somewhere, please emails me at &lt;strong&gt;nikatsanka@gmail.com&lt;/strong&gt;&lt;/p&gt;</content></entry></feed>